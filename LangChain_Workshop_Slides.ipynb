{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c00e2f9",
   "metadata": {},
   "source": [
    "\n",
    "# Mastering LangChain: Enhancing LLM Applications with Advanced Workflows\n",
    "### Presentation Outline\n",
    "This workshop covers the setup and advanced use of LangChain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26d32aa",
   "metadata": {},
   "source": [
    "\n",
    "## Slide: Setting Up Environment\n",
    "\n",
    "Set up your Python environment for LangChain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Environment Setup\n",
    "!python3 -m venv langchain-env\n",
    "!source langchain-env/bin/activate\n",
    "!pip install langchain openai faiss-cpu\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda531f2",
   "metadata": {},
   "source": [
    "\n",
    "## Slide: Chains - Sequential Operations\n",
    "\n",
    "LangChain uses chains of operations to create custom workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a0d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chains: Sequential Operations\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "prompt = PromptTemplate(template=\"What is {topic}?\", input_variables=[\"topic\"])\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "result = chain.run(topic=\"LangChain\")\n",
    "print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b4a2b",
   "metadata": {},
   "source": [
    "\n",
    "## Slide: Agents - Dynamic Decision-Making\n",
    "\n",
    "Agents in LangChain can dynamically make decisions and interact with external systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ef971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Agents: Dynamic Decision-Making\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.tools import WebSearchTool\n",
    "\n",
    "search = WebSearchTool()\n",
    "agent = create_openai_functions_agent(llm, tools=[search])\n",
    "agent.run(\"What's the latest news on LangChain?\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d3fcbb",
   "metadata": {},
   "source": [
    "\n",
    "## Slide: Memory - Retaining Context\n",
    "\n",
    "LangChain supports memory to retain context across interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Memory: Retaining Context Over Interactions\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(llm=llm, memory=memory)\n",
    "response = conversation.predict(input=\"Hello, who am I?\")\n",
    "response2 = conversation.predict(input=\"What did I ask previously?\")\n",
    "print(response2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1304c8",
   "metadata": {},
   "source": [
    "\n",
    "## Slide: Retrievers - Retrieving Relevant Information\n",
    "\n",
    "Use FAISS and other tools to efficiently retrieve relevant information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64629a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Retrievers: Using FAISS for Document Retrieval\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "documents = [\"document 1 content\", \"document 2 content\"]\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "faiss_index = FAISS.from_texts(documents, embedding_model)\n",
    "\n",
    "query = \"find document 1\"\n",
    "results = faiss_index.similarity_search(query)\n",
    "print(results[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5db9478",
   "metadata": {},
   "source": [
    "\n",
    "## Slide: Multi-Step Workflows - Combining Various Tools\n",
    "\n",
    "LangChain can handle complex tasks by combining multiple tools and workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fabf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Building Multi-Step Workflows\n",
    "from langchain.chains import SimpleChain\n",
    "\n",
    "chain1 = LLMChain(llm=llm, prompt=PromptTemplate.from_template(\"Step 1: {task}\"))\n",
    "chain2 = LLMChain(llm=llm, prompt=PromptTemplate.from_template(\"Step 2: {task}\"))\n",
    "\n",
    "multi_step_chain = SimpleChain(chains=[chain1, chain2])\n",
    "multi_step_chain.run(task=\"Start the workflow\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b67fd2",
   "metadata": {},
   "source": [
    "\n",
    "## Slide: Connecting to APIs\n",
    "\n",
    "LangChain allows connecting to external APIs and retrieving information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac40c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connecting to External APIs\n",
    "import requests\n",
    "\n",
    "api_url = \"http://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q=San Francisco\"\n",
    "response = requests.get(api_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(f\"Current temperature: {data['current']['temp_c']}Â°C\")\n",
    "else:\n",
    "    print(\"Failed to retrieve data\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48f040e",
   "metadata": {},
   "source": [
    "\n",
    "## Slide: RAG System - Retriever-Augmented Generation\n",
    "\n",
    "Use LangChain's RAG system to retrieve and generate answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f0b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Building a RAG System (Retriever-Augmented Generation)\n",
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.qa import QASystem\n",
    "\n",
    "retriever = SVMRetriever(vectorstore=faiss_index)\n",
    "qa_system = QASystem(retriever=retriever, llm=llm)\n",
    "response = qa_system.ask(\"What is document 1 about?\")\n",
    "print(response)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddc90e7",
   "metadata": {},
   "source": [
    "\n",
    "## Slide: Best Practices for Production Use\n",
    "\n",
    "Follow these best practices when deploying LangChain in production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a16ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Best Practices in Production\n",
    "\n",
    "# Version Control\n",
    "# Ensure LangChain scripts and models are versioned using Git.\n",
    "\n",
    "# Testing\n",
    "# Use pytest to write unit tests for chains, agents, and retrievers.\n",
    "\n",
    "# Documentation\n",
    "# Use markdown for maintaining detailed project documentation.\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
